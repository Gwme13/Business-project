{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e7b1bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gemel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gemel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import contractions\n",
    "from fpdf import FPDF\n",
    "from PIL import Image\n",
    "import nltk\n",
    "import google.generativeai as genai\n",
    "import filters\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_en = stopwords.words('english')\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d78f9991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentiment_analysis(text):\n",
    "    # Find sentiment section\n",
    "    sentiment_section = re.search(r\"\\*\\*2[)]?[.]?\\s[^:]+:\\*\\*(.*?)$\", text, re.DOTALL)\n",
    "    \n",
    "    if not sentiment_section:\n",
    "        return []\n",
    "\n",
    "    \n",
    "    # Extract sentiment text\n",
    "    sentiment_text = sentiment_section.group(1)\n",
    "\n",
    "    # Define pattern to extract topic, positive and negative percentages\n",
    "    pattern = re.compile(r\"^\\*\\s\\*\\*([^:]+):\\*\\*\\s\\*\\*([\\d]+)%\\spositive,\\s([\\d]+)%\\snegative\\.\\*\\*\", re.MULTILINE)\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    # Extract sentiment analysis    \n",
    "    for match in pattern.findall(sentiment_text):\n",
    "        topic = match[0].strip()\n",
    "        positive = int(match[1])\n",
    "        negative = int(match[2])\n",
    "        results.append({'topic': topic, 'positive': positive, 'negative': negative})\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "134c2e9e-6fed-48d0-865c-c4095baf9dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset_and_get_results(dataset_path, output_pdf, api_key=None, company_name=None, review_col='review', rating_col='rating'):\n",
    "    \n",
    "    df = {}\n",
    "\n",
    "    # try to read the dataset with the 'utf-8' encoding\n",
    "    try:\n",
    "        df = pd.read_csv(dataset_path, encoding='utf-8')\n",
    "    \n",
    "    except Exception as e:\n",
    "        # if an error occurs, try reading the dataset with 'latin1' encoding\n",
    "        try:\n",
    "            df = pd.read_csv(dataset_path, encoding='latin1')\n",
    "        except Exception as e:\n",
    "            print(\"Error reading the dataset:\", e)\n",
    "            return\n",
    "\n",
    "    # check if the review and rating columns are present in the dataset\n",
    "    if review_col not in df.columns or rating_col not in df.columns:\n",
    "        print(f\"Error: '{review_col}' or '{rating_col}' columns not found in the dataset.\")\n",
    "        return\n",
    "\n",
    "    # check if the company_name is provided\n",
    "    if company_name is None:\n",
    "        print(\"Error: 'company_name' is required.\")\n",
    "        return\n",
    "\n",
    "    # check if the api_key is provided\n",
    "    if api_key is None:\n",
    "        print(\"Error: 'api_key' is required.\")\n",
    "    \n",
    "    print(\"Dataset loaded successfully.\")\n",
    "    print(\"\\n\")\n",
    "    print(\"Processing the dataset...\")    \n",
    "\n",
    "    # PREPROCESSING ADDIZIONALE\n",
    "\n",
    "    # Rimozione di spazi bianchi iniziali/finali da tutte le colonne di testo\n",
    "    df[review_col] = df[review_col].str.strip()\n",
    "\n",
    "    # Rimozione di eventuali valori NaN nelle colonne rating e review\n",
    "    df = df.dropna(subset=[review_col, rating_col])\n",
    "\n",
    "    # Trasformiamo i rating in interi, se non lo sono giÃ \n",
    "    df[rating_col] = pd.to_numeric(df[rating_col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Visualizzazione distribuzione delle categorie (rating)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.countplot(x=rating_col, data=df, order=df[rating_col].value_counts().index, palette='viridis')\n",
    "    plt.title('Rating Distribution')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('Rating')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('rating_distribution.png', format='png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Converting reviews to lowercase\n",
    "    df[review_col] = df[review_col].str.lower()\n",
    "\n",
    "    \n",
    "    # Applying filter string (if custom filter exists)\n",
    "    df[review_col] = df[review_col].apply(filters.filter_string)\n",
    "\n",
    "    # Fix contractions (e.g., \"don't\" -> \"do not\")\n",
    "    df[review_col] = df[review_col].apply(contractions.fix)\n",
    "\n",
    "    # Tokenization\n",
    "    df['tokenized_review'] = df[review_col].apply(lambda text: nltk.word_tokenize(text))\n",
    "\n",
    "    # Removing stopwords\n",
    "    df['tokenized_review'] = df['tokenized_review'].apply(lambda tokens: [token for token in tokens if token not in stopwords_en])\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    df['tokenized_review'] = df['tokenized_review'].apply(lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])\n",
    "\n",
    "    # WordCloud\n",
    "    wordcloud = WordCloud(width=800, height=800, background_color='white', stopwords=stopwords_en, min_font_size=10).generate(' '.join(df['tokenized_review'].apply(lambda tokens: ' '.join(tokens))))\n",
    "    \n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title('Most Common Words in Reviews')\n",
    "    plt.savefig('wordcloud.png', format='png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"Preprocessing completed.\")\n",
    "    print(\"\\n\")\n",
    "    print(\"GeminAI API Integration\")\n",
    "    \n",
    "    prompt = f\"\"\" \n",
    "    You are a virtual assistant to the CEO of {company_name}. I will provide you with reviews in text format. Analyze them and provide:\n",
    "        1) Main Topics.\n",
    "        2) Assign a rank of positive or negative to each tpoci you find as percentage (e.g., 80% positive, 20% negative). Write following the format: * **Topic:** **80% positive, 20% negative.**\n",
    "        3) For the formulation of a new strategy in business, identify my company's main problems (worst topic: give it after the topic extraction and write \"Worst topic: ...\") and propose technical-economic feedback.\n",
    "        \n",
    "        Provide a detailed analysis.\n",
    "    \"\"\"\n",
    "        \n",
    "    genai.configure(api_key=api_key)\n",
    "    \n",
    "    model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "    \n",
    "    # write the reviews to a text file\n",
    "    with open('reviews.txt', 'w') as f:\n",
    "        f.write('\\n'.join(df[review_col]))\n",
    "        \n",
    "    sample_file = genai.upload_file(path='reviews.txt', display_name='reviews.txt')\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(f\"Uploaded file '{sample_file.display_name}'\")\n",
    "    print(\"\\n\")\n",
    "    print(\"Generating content...\")\n",
    "    \n",
    "    os.remove('reviews.txt')\n",
    "\n",
    "    # Generate content using the uploaded document\n",
    "    response = model.generate_content([sample_file, prompt])\n",
    "\n",
    "    # Save the response to a text file\n",
    "    with open('output.txt', 'w') as f:\n",
    "        f.write(response.text)\n",
    "        \n",
    "    \n",
    "    results = extract_sentiment_analysis(response.text)\n",
    "    \n",
    "    \n",
    "    # If results is not empty, plot the sentiment scores\n",
    "    if results:\n",
    "        topics = [result['topic'] for result in results]\n",
    "        positive_scores = [result['positive'] for result in results]\n",
    "        negative_scores = [result['negative'] for result in results]\n",
    "        \n",
    "        palette = sns.color_palette('viridis', 2)\n",
    "        \n",
    "        bar_width = 0.35\n",
    "        r1 = np.arange(len(topics))\n",
    "        r2 = [x + bar_width for x in r1]\n",
    "\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.bar(r1, positive_scores, color=palette[1], label='Positive', width=bar_width)\n",
    "        plt.bar(r2, negative_scores, color=palette[0], label='Negative', width=bar_width)\n",
    "        \n",
    "        plt.xlabel('Topic')\n",
    "        plt.ylabel('Percentage')\n",
    "        plt.title('Positive vs Negative Scores per Topic', fontsize=14)\n",
    "        \n",
    "        plt.xticks([r + bar_width/2 for r in r1], topics, rotation=45)\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the plot to a file\n",
    "        plt.savefig('sentiment_analysis.png', format='png', bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"\\n\")     \n",
    "    print(\"Content generated successfully.\")\n",
    "    print(\"\\n\")\n",
    "    print(\"Generating PDF report...\")\n",
    "    \n",
    "\n",
    "    pdf = FPDF()\n",
    "    pdf.set_auto_page_break(auto=True, margin=15)\n",
    "\n",
    "    pdf.add_page()\n",
    "    \n",
    "    pdf.set_font(\"Arial\", size=11)\n",
    "\n",
    "    # Read the text from the output file and write it to the PDF\n",
    "    with open('output.txt', 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            pdf.multi_cell(0, 10, line)  # Allow for multi-line text\n",
    "    \n",
    "    \n",
    "    os.remove('output.txt')\n",
    "\n",
    "    pdf.add_page()\n",
    "\n",
    "    # Add the rating distribution image to the PDF\n",
    "    image = Image.open('rating_distribution.png')\n",
    "    image_width, image_height = image.size\n",
    "    max_width, max_height = 100, 100\n",
    "\n",
    "    width_ratio = max_width / image_width\n",
    "    height_ratio = max_height / image_height\n",
    "    scale_ratio = min(width_ratio, height_ratio)\n",
    "\n",
    "    new_width = int(image_width * scale_ratio)\n",
    "    new_height = int(image_height * scale_ratio)\n",
    "\n",
    "    pdf.image('rating_distribution.png', x=10, y=None, w=new_width, h=new_height)\n",
    "    \n",
    "    # Add the word cloud image to the PDF\n",
    "    image = Image.open('wordcloud.png')\n",
    "    image_width, image_height = image.size\n",
    "    max_width, max_height = 100, 100\n",
    "    \n",
    "    width_ratio = max_width / image_width\n",
    "    height_ratio = max_height / image_height\n",
    "    scale_ratio = min(width_ratio, height_ratio)\n",
    "    \n",
    "    new_width = int(image_width * scale_ratio)\n",
    "    new_height = int(image_height * scale_ratio)\n",
    "    \n",
    "    pdf.image('wordcloud.png', x=10, y=None, w=new_width, h=new_height)\n",
    "    \n",
    "    \n",
    "    # Add the sentiment analysis image to the PDF\n",
    "    image = Image.open('sentiment_analysis.png')\n",
    "    image_width, image_height = image.size\n",
    "    max_width, max_height = 200, 200\n",
    "    \n",
    "    width_ratio = max_width / image_width\n",
    "    height_ratio = max_height / image_height\n",
    "    scale_ratio = min(width_ratio, height_ratio)\n",
    "    \n",
    "    new_width = int(image_width * scale_ratio)\n",
    "    new_height = int(image_height * scale_ratio)\n",
    "    \n",
    "    pdf.image('sentiment_analysis.png', x=10, y=None, w=new_width, h=new_height)\n",
    "    \n",
    "    # Save the final PDF\n",
    "    pdf.output(output_pdf)\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "436b13ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: customtkinter in c:\\users\\gemel\\anaconda3\\envs\\dmml\\lib\\site-packages (5.2.2)\n",
      "Requirement already satisfied: darkdetect in c:\\users\\gemel\\anaconda3\\envs\\dmml\\lib\\site-packages (from customtkinter) (0.8.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\gemel\\anaconda3\\envs\\dmml\\lib\\site-packages (from customtkinter) (23.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install customtkinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf5c84ff-9ece-49bb-aa7d-12f97cbc0c2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TclError",
     "evalue": "image \"pyimage8\" doesn't exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 98\u001b[0m\n\u001b[0;32m     95\u001b[0m logo_img \u001b[38;5;241m=\u001b[39m logo_img\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m200\u001b[39m), Image\u001b[38;5;241m.\u001b[39mLANCZOS)\n\u001b[0;32m     97\u001b[0m logo_photo \u001b[38;5;241m=\u001b[39m ImageTk\u001b[38;5;241m.\u001b[39mPhotoImage(logo_img)  \u001b[38;5;66;03m# Mantieni un riferimento all'immagine\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m logo_label \u001b[38;5;241m=\u001b[39m \u001b[43mctk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCTkLabel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogo_photo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m logo_label\u001b[38;5;241m.\u001b[39mgrid(row\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, column\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, pady\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# Section to load the dataset file\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gemel\\anaconda3\\envs\\DMML\\Lib\\site-packages\\customtkinter\\windows\\widgets\\ctk_label.py:104\u001b[0m, in \u001b[0;36mCTkLabel.__init__\u001b[1;34m(self, master, width, height, corner_radius, bg_color, fg_color, text_color, text_color_disabled, text, font, image, compound, anchor, wraplength, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m check_kwargs_empty(kwargs, raise_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_grid()\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_draw()\n",
      "File \u001b[1;32mc:\\Users\\gemel\\anaconda3\\envs\\DMML\\Lib\\site-packages\\customtkinter\\windows\\widgets\\ctk_label.py:144\u001b[0m, in \u001b[0;36mCTkLabel._update_image\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label\u001b[38;5;241m.\u001b[39mconfigure(image\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_image\u001b[38;5;241m.\u001b[39mcreate_scaled_photo_image(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_widget_scaling(),\n\u001b[0;32m    142\u001b[0m                                                                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_appearance_mode()))\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_label\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfigure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_image\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gemel\\anaconda3\\envs\\DMML\\Lib\\tkinter\\__init__.py:1702\u001b[0m, in \u001b[0;36mMisc.configure\u001b[1;34m(self, cnf, **kw)\u001b[0m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfigure\u001b[39m(\u001b[38;5;28mself\u001b[39m, cnf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m   1696\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Configure resources of a widget.\u001b[39;00m\n\u001b[0;32m   1697\u001b[0m \n\u001b[0;32m   1698\u001b[0m \u001b[38;5;124;03m    The values for resources are specified as keyword\u001b[39;00m\n\u001b[0;32m   1699\u001b[0m \u001b[38;5;124;03m    arguments. To get an overview about\u001b[39;00m\n\u001b[0;32m   1700\u001b[0m \u001b[38;5;124;03m    the allowed keyword arguments call the method keys.\u001b[39;00m\n\u001b[0;32m   1701\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_configure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconfigure\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcnf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gemel\\anaconda3\\envs\\DMML\\Lib\\tkinter\\__init__.py:1692\u001b[0m, in \u001b[0;36mMisc._configure\u001b[1;34m(self, cmd, cnf, kw)\u001b[0m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cnf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1691\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getconfigure1(_flatten((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_w, cmd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mcnf)))\n\u001b[1;32m-> 1692\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTclError\u001b[0m: image \"pyimage8\" doesn't exist"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import customtkinter as ctk\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# Function to load the dataset file\n",
    "def load_file():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"CSV files\", \"*.csv\")])\n",
    "    if file_path:\n",
    "        dataset_path.set(file_path)\n",
    "        file_label.configure(text=f\"File loaded: {os.path.basename(file_path)}\")\n",
    "    else:\n",
    "        file_label.configure(text=\"No file selected.\")\n",
    "\n",
    "# Function to start the analysis\n",
    "def start_analysis():\n",
    "    if not dataset_path.get() or not review_col_entry.get() or not rating_col_entry.get():\n",
    "        messagebox.showwarning(\"Warning\", \"Fill in all fields and select a dataset!\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Insert your function to process the dataset here\n",
    "        process_dataset_and_get_results(\n",
    "            dataset_path.get(),\n",
    "            \"output.pdf\",\n",
    "            api_key,\n",
    "            company_name=company_name.get(),\n",
    "            review_col=review_col_entry.get(),\n",
    "            rating_col=rating_col_entry.get()\n",
    "        )\n",
    "\n",
    "        # Display the results of the analysis\n",
    "        result_label.configure(text=\"Analysis complete. Download the PDF or view the charts.\")\n",
    "      \n",
    "        show_images()  # Function to display the charts\n",
    "        download_button.grid(row=8, column=1, pady=10)  # Make the button visible\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"An error occurred during the analysis: {e}\")\n",
    "        show_images()  # Function to display the charts\n",
    "        download_button.grid(row=8, column=1, pady=10)  # Make the button visible\n",
    "\n",
    "# Function to display the images (charts)\n",
    "def show_images():\n",
    "    try:\n",
    "        # Load and display saved images (charts)\n",
    "        rating_img = Image.open(\"rating_distribution.png\")\n",
    "        wordcloud_img = Image.open(\"wordcloud.png\")\n",
    "        sentiment_img = Image.open(\"sentiment_analysis.png\")\n",
    "\n",
    "        # Replace Image.ANTIALIAS with Image.Resampling.LANCZOS\n",
    "        rating_img = rating_img.resize((400, 400), Image.Resampling.LANCZOS)\n",
    "        wordcloud_img = wordcloud_img.resize((400, 400), Image.Resampling.LANCZOS)\n",
    "        sentiment_img = sentiment_img.resize((600, 400), Image.Resampling.LANCZOS)\n",
    "\n",
    "        rating_photo = ImageTk.PhotoImage(rating_img)\n",
    "        wordcloud_photo = ImageTk.PhotoImage(wordcloud_img)\n",
    "        sentiment_photo = ImageTk.PhotoImage(sentiment_img)\n",
    "\n",
    "        rating_label.configure(image=rating_photo)\n",
    "        rating_label.image = rating_photo\n",
    "\n",
    "        wordcloud_label.configure(image=wordcloud_photo)\n",
    "        wordcloud_label.image = wordcloud_photo\n",
    "        \n",
    "        sentiment_label.configure(image=sentiment_photo)\n",
    "        sentiment_label.image = sentiment_photo\n",
    "        \n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"Error loading images: {e}\")\n",
    "\n",
    "# Function to download the PDF\n",
    "def download_pdf():\n",
    "    pdf_path = filedialog.asksaveasfilename(defaultextension=\".pdf\", filetypes=[(\"PDF files\", \"*.pdf\")])\n",
    "    if pdf_path:\n",
    "        os.rename(\"output.pdf\", pdf_path)\n",
    "        messagebox.showinfo(\"Success\", \"PDF downloaded successfully!\")\n",
    "\n",
    "# Configure the main window\n",
    "app = ctk.CTk()\n",
    "app.title(\"Echo Tips\")\n",
    "app.geometry(\"900x600\")\n",
    "\n",
    "# Input variables\n",
    "dataset_path = tk.StringVar()\n",
    "api_key = \"AIzaSyBzjTSU97Yedj0yo5GDLxuUQVxxCWDunVk\"  # Use protected variables for the API key\n",
    "company_name = tk.StringVar(value=\"ENTER_COMPANY_NAME\")\n",
    "\n",
    "# Title\n",
    "title_label = ctk.CTkLabel(app, text=\"     Hear the Feedback, Take the Right Step\", font=(\"Arial\", 24, \"bold\"))\n",
    "title_label.grid(row=0, column=0, columnspan=2, pady=20)\n",
    "\n",
    "# Section to load the dataset file\n",
    "file_button = ctk.CTkButton(app, text=\"Load Dataset (CSV)\", command=load_file)\n",
    "file_button.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "file_label = ctk.CTkLabel(app, text=\"No file selected.\")\n",
    "file_label.grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "# Field to enter the name of the \"review\" column\n",
    "review_col_label = ctk.CTkLabel(app, text=\"Review Column:\", font=(\"Arial\", 14))\n",
    "review_col_label.grid(row=2, column=0, padx=10, pady=10)\n",
    "\n",
    "review_col_entry = ctk.CTkEntry(app, width=200)\n",
    "review_col_entry.grid(row=2, column=1, padx=10, pady=10)\n",
    "\n",
    "# Field to enter the name of the \"rating\" column\n",
    "rating_col_label = ctk.CTkLabel(app, text=\"Rating Column:\", font=(\"Arial\", 14))\n",
    "rating_col_label.grid(row=3, column=0, padx=10, pady=10)\n",
    "\n",
    "rating_col_entry = ctk.CTkEntry(app, width=200)\n",
    "rating_col_entry.grid(row=3, column=1, padx=10, pady=10)\n",
    "\n",
    "# Field to enter the company name\n",
    "company_label = ctk.CTkLabel(app, text=\"Company Name:\", font=(\"Arial\", 14))\n",
    "company_label.grid(row=4, column=0, padx=10, pady=10)\n",
    "\n",
    "company_entry = ctk.CTkEntry(app, textvariable=company_name, width=200)\n",
    "company_entry.grid(row=4, column=1, padx=10, pady=10)\n",
    "\n",
    "# Button to start the analysis\n",
    "start_button = ctk.CTkButton(app, text=\"Start Analysis\", command=start_analysis)\n",
    "start_button.grid(row=5, column=0, columnspan=2, pady=20)\n",
    "\n",
    "# Label to show the results of the analysis\n",
    "result_label = ctk.CTkLabel(app, text=\"\", font=(\"Arial\", 14, \"bold\"))\n",
    "result_label.grid(row=6, column=0, columnspan=2, pady=10)\n",
    "\n",
    "# Section to display the charts\n",
    "rating_label = ctk.CTkLabel(app, text=\"\")\n",
    "rating_label.grid(row=7, column=0, padx=10, pady=10)\n",
    "\n",
    "wordcloud_label = ctk.CTkLabel(app, text=\"\")\n",
    "wordcloud_label.grid(row=7, column=1, padx=10, pady=10)\n",
    "\n",
    "sentiment_label = ctk.CTkLabel(app, text=\"\")\n",
    "sentiment_label.grid(row=7, column=2, padx=10, pady=10)\n",
    "\n",
    "# Button to download the PDF\n",
    "download_button = ctk.CTkButton(app, text=\"Download PDF\", command=download_pdf)\n",
    "download_button.grid(row=8, column=1, pady=10)\n",
    "download_button.grid_remove()  # Hide the button until the end of the analysis\n",
    "\n",
    "# Start the GUI\n",
    "app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf045bc-254c-4598-ac26-f7e53064a6b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
